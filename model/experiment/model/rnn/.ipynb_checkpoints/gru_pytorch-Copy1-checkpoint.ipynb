{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8e5f5bde-3ca3-4262-85db-776a54590e7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "import torch.optim as optim\n",
    "\n",
    "import time\n",
    "import datetime\n",
    "import os\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1010198b-a602-46ec-88bc-b5e8f80a2b4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_dir = \"Results\"\n",
    "if not os.path.exists(result_dir):\n",
    "    os.makedirs(result_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "106cc485-510a-4dfa-bcb4-19359465c40b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(object):\n",
    "    def __init__(self, path, itemMap=None):\n",
    "        self.sessionKey = 'SessionId'\n",
    "        self.itemKey = 'ItemId'\n",
    "        self.timeKey = 'Time'\n",
    "        self.ItemIdx = 'ItemIdx'\n",
    "        self.data = pd.read_csv(path, sep=',', dtype={self.sessionKey: int, self.itemKey: int, self.timeKey: float})\n",
    "\n",
    "        # アイテムマップの作成し結合（評価時は学習データのアイテムマップを使用する）\n",
    "        self.itemMap = itemMap;\n",
    "        if (self.itemMap is None):\n",
    "            itemIds = self.data[self.itemKey].unique()\n",
    "            itemMap = pd.Series(data=np.arange(len(itemIds)), index=itemIds);\n",
    "            item_indices = itemMap[itemIds].values\n",
    "            itemDict = {\n",
    "                self.itemKey: itemIds,\n",
    "                self.ItemIdx: item_indices\n",
    "            }\n",
    "            self.itemMap = pd.DataFrame(itemDict)\n",
    "        self.data = pd.merge(self.data, self.itemMap, on=self.itemKey, how='inner')\n",
    "        \n",
    "        # セッション数の累積合計リスト（セッションの開始位置リスト）を取得\n",
    "        self.data.sort_values([self.sessionKey, self.timeKey], inplace=True)\n",
    "        session_nItem = self.data.groupby(self.sessionKey).size()\n",
    "        cum_session_nItem = session_nItem.cumsum()\n",
    "        self.sessionsArray = np.r_[0, cum_session_nItem.values]\n",
    "\n",
    "        self.nItems = len(self.itemMap)\n",
    "\n",
    "class DataGenerator():\n",
    "    def __init__(self, dataset, nSample=2048):\n",
    "        self.data = dataset.data\n",
    "        self.nItems = dataset.nItems\n",
    "        self.sessionsArray = dataset.sessionsArray\n",
    "\n",
    "        self.batchSize = 32\n",
    "        self.nSample = nSample   \n",
    "        self.sampleAlpha = 0.75\n",
    "        self.sampleBuffer = 10000000\n",
    "        \n",
    "        if self.nSample:\n",
    "            self.popularArray = self.createPopular(dataset.itemMap, dataset.itemKey);\n",
    "        self.sessionIdxArr = np.argsort(self.data.groupby(dataset.sessionKey)[dataset.timeKey].min().values) \n",
    "        self.totalIters = ((len(self.data) - len(self.sessionsArray)) // self.batchSize)\n",
    "\n",
    "    def __iter__(self):\n",
    "        dataItems = self.data.ItemIdx.values;\n",
    "        sessionsArray = self.sessionsArray\n",
    "        sessionIdxArr = self.sessionIdxArr\n",
    "        \n",
    "        iters = np.arange(self.batchSize)\n",
    "        maxiter = iters.max()\n",
    "        start = sessionsArray[sessionIdxArr[iters]]\n",
    "        end = sessionsArray[sessionIdxArr[iters] + 1]      \n",
    "        nSessions = len(sessionsArray) - 1\n",
    "        \n",
    "        finished = False\n",
    "        finishedMask = (end - start <= 1)\n",
    "        validMask = (iters < nSessions)\n",
    "        \n",
    "        while not finished:\n",
    "            minlen = (end - start).min()\n",
    "            outIdx = dataItems[start]\n",
    "\n",
    "            for i in range(minlen - 1):\n",
    "                inIdx = outIdx\n",
    "                outIdx = dataItems[start + i + 1]\n",
    "                if (self.nSample):\n",
    "                    if(self.sampleBuffer):\n",
    "                        if(self.samplePointer == self.generatelength):\n",
    "                            self.negativSamples = self.generateNegSamples(self.popularArray, self.generatelength)\n",
    "                            self.samplePointer = 0\n",
    "                        sample = self.negativSamples[self.samplePointer]\n",
    "                        self.samplePointer += 1;\n",
    "                    else:\n",
    "                        sample = self.generateNegSamples(self.pop, 1);\n",
    "                    y = np.hstack([outIdx, sample])\n",
    "                else:\n",
    "                    y = outIdx;\n",
    "                    \n",
    "                input = torch.LongTensor(inIdx)\n",
    "                target = torch.LongTensor(y)\n",
    "                yield input, target, finishedMask, validMask\n",
    "                                \n",
    "                finishedMask[:] = False;\n",
    "                validMask[:] = True\n",
    "                \n",
    "            start = start + minlen - 1\n",
    "            finishedMask = (end - start <= 1)\n",
    "            nFinished = finishedMask.sum()\n",
    "            iters[finishedMask] = maxiter + np.arange(1, nFinished + 1)\n",
    "            maxiter += nFinished;\n",
    "            \n",
    "            validMask = (iters < nSessions)\n",
    "            nValid = validMask.sum()\n",
    "            \n",
    "            if (nValid == 0):\n",
    "                finished = True;\n",
    "                break;\n",
    "   \n",
    "            iters[~validMask] = 0;         \n",
    "            sessions = sessionIdxArr[iters[finishedMask]]\n",
    "            start[finishedMask] = sessionsArray[sessions]\n",
    "            end[finishedMask] = sessionsArray[sessions + 1]\n",
    "            iters = iters[validMask]\n",
    "            start = start[validMask]\n",
    "            end = end[validMask]\n",
    "\n",
    "    def generateNegSamples(self, popularArray, length):\n",
    "        sample = np.searchsorted(popularArray, np.random.rand(self.nSample * length))\n",
    "        if length > 1:\n",
    "            sample = sample.reshape((length, self.nSample))\n",
    "        return sample\n",
    "\n",
    "    def createPopular(self, itemMap, itemKey):\n",
    "        popularArray = self.data.groupby(itemKey).size()\n",
    "        itemIds = itemMap.loc[:, itemKey].values\n",
    "\n",
    "        print(popularArray)\n",
    "        \n",
    "        # 人気度の確率分布を作成\n",
    "        popularArray = popularArray[itemIds].values ** self.sampleAlpha\n",
    "        popularArray = popularArray.cumsum() / popularArray.sum()\n",
    "\n",
    "        # ネガティブサンプリング\n",
    "        self.generatelength = (self.sampleBuffer // self.nSample)\n",
    "        self.negativSamples = np.searchsorted(popularArray, np.random.rand(self.nSample * self.generatelength))\n",
    "        self.negativSamples = self.negativSamples.reshape((self.generatelength, self.nSample))\n",
    "\n",
    "        self.samplePointer = 0\n",
    "\n",
    "        return popularArray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "953f0f6b-5202-45a7-b16c-7cac1ac6a725",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataFolder = '../../../data/'\n",
    "trainDataFile = 'Train.csv'\n",
    "validDataFile = 'Valid.csv'\n",
    "\n",
    "sessionKey = 'SessionId';\n",
    "itemKey = 'ItemId';\n",
    "timeKey = 'Time';\n",
    "\n",
    "trainPath = os.path.join(dataFolder, trainDataFile)\n",
    "validPath = os.path.join(dataFolder, validDataFile)\n",
    "\n",
    "trainDataSet = Dataset(trainPath)\n",
    "validDataSet = Dataset(validPath, itemMap=trainDataSet.itemMap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e2aaedc4-bed8-4a46-929d-c162369afff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GRU4Rec(nn.Module):\n",
    "    def __init__(self, inputSize, outputSize):\n",
    "\n",
    "        super(GRU4Rec, self).__init__()\n",
    "\n",
    "        self.inputSize = inputSize\n",
    "        self.outputSize = outputSize\n",
    "        self.batchSize = 32\n",
    "        self.hiddenSize = 100\n",
    "        self.nLayers = 1\n",
    "        self.sigma = 0.0\n",
    "        self.negative = True\n",
    "\n",
    "        self.embeddingDim = -1\n",
    "        \n",
    "        self.dropoutHidden = 0.0\n",
    "        self.dropoutEmbed = 0.0\n",
    "        self.initAsNormal = False\n",
    "        \n",
    "        self.device = torch.device('cuda' if torch.cuda.is_available()  else 'cpu')\n",
    "\n",
    "        self.gru = nn.GRU(self.inputSize, self.hiddenSize, self.nLayers, bias=False, dropout=self.dropoutHidden)\n",
    "        self.onehotBuffer = torch.FloatTensor(self.batchSize, self.outputSize)\n",
    "        self.linear = nn.Linear(self.hiddenSize, self.outputSize)\n",
    "        self.Tanh = nn.Tanh()\n",
    "\n",
    "        self.initParams();\n",
    "        \n",
    "        self = self.to(self.device)\n",
    "\n",
    "    def forward(self, input, hidden, target=None):\n",
    "\n",
    "        # 1-of-Nエンコーディング\n",
    "        embedded = self.onehotEncode(input)\n",
    "        embedded = embedded.unsqueeze(0)\n",
    "\n",
    "        \n",
    "        output, hNew = self.gru(embedded, hidden) \n",
    "        output = output.view(-1, output.size(-1))                   \n",
    "        output = self.linear(output) \n",
    "        output = self.Tanh(output)\n",
    "        \n",
    "        return output, hNew\n",
    "\n",
    "    def onehotEncode(self, input):\n",
    "        \n",
    "        self.onehotBuffer.zero_()\n",
    "        index = input.view(-1, 1)\n",
    "        onehot = self.onehotBuffer[:len(index)].scatter_(1, index, 1)\n",
    "        \n",
    "        return onehot\n",
    "\n",
    "    def initHidden(self, batchSize):\n",
    "        h0 = torch.zeros(self.nLayers, int(batchSize), self.hiddenSize).to(self.device)\n",
    "        return h0\n",
    "    \n",
    "    def resetHidden(self, hidden, finishedMask, validMask):\n",
    "        if any(finishedMask):\n",
    "            hidden[:, finishedMask, :] = 0 \n",
    "\n",
    "        if any((~validMask)):\n",
    "            hidden = hidden[:, validMask, :]\n",
    "            \n",
    "        return hidden.data;\n",
    "    \n",
    "    def initParams(self):\n",
    "        for name, param in self.gru.named_parameters():\n",
    "            if 'weight' in name:\n",
    "                WR, WZ, WN = param.chunk(3, 0)\n",
    "                self.initMatrix(WR)\n",
    "                self.initMatrix(WZ)\n",
    "                self.initMatrix(WN)\n",
    "    \n",
    "            elif 'bias' in name :\n",
    "                param.data.zero_()\n",
    "        \n",
    "        self.initMatrix(self.linear.weight)\n",
    "        self.linear.bias.data.zero_()\n",
    "        \n",
    "    def initMatrix(self, param):\n",
    "        \n",
    "        shape = list(param.shape)\n",
    "        sigma = np.sqrt(6.0 / np.sum(shape))\n",
    "        param.data.uniform_(-sigma, sigma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f35f42eb-85b1-4f4e-a6a0-a69ab013911f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LossFunction(nn.Module):\n",
    "    def __init__(self, lossType='top1', useCuda=True, bpreg=1.0):\n",
    "        \n",
    "        super(LossFunction, self).__init__()\n",
    "        self.lossType = lossType\n",
    "        self.useCuda = useCuda\n",
    "        lossType = lossType.lower()\n",
    "\n",
    "        if lossType == 'top1':\n",
    "            self._lossFn = TOP1Loss()\n",
    "        else:\n",
    "            raise NotImplementedError\n",
    "\n",
    "    def forward(self, input, target=None):\n",
    "        return self._lossFn(input, target)\n",
    "\n",
    "class TOP1Loss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(TOP1Loss, self).__init__()\n",
    "    def forward(self, input, target=None):\n",
    "        diff = -(input.diag().view(-1, 1).expand_as(input) - input)\n",
    "        loss = torch.sigmoid(diff).mean() + torch.sigmoid(input ** 2).mean()\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "009bef42-3623-4380-86c1-0e38731049dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Optimizer:\n",
    "    def __init__(self, params, optimizerType='adagrad', lr=0.05, momentum=0, weightDecay=0, eps=1e-6):\n",
    "\n",
    "        optimizerType = optimizerType.lower()\n",
    "        if optimizerType == 'adagrad':\n",
    "            self.optimizer = optim.Adagrad(params, lr=lr, weight_decay=weightDecay, eps=1e-6)\n",
    "        else:\n",
    "            raise NotImplementedError\n",
    "\n",
    "    def zero_grad(self):\n",
    "        self.optimizer.zero_grad()\n",
    "\n",
    "    def step(self):\n",
    "        self.optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "25a31eba-5ed2-461a-a80c-78f5181f0ff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getRecall(indices, targets): \n",
    "    targets = targets.view(-1, 1).expand_as(indices)\n",
    "    hits = (targets == indices).nonzero()\n",
    "    if len(hits) == 0:\n",
    "        return 0\n",
    "    n_hits = (targets == indices).nonzero()[:, :-1].size(0)\n",
    "    recall = float(n_hits) / targets.size(0)\n",
    "    return recall\n",
    "\n",
    "def getMrr(indices, targets):\n",
    "    tmp = targets.view(-1, 1)\n",
    "    targets = tmp.expand_as(indices)\n",
    "    hits = (targets == indices).nonzero()\n",
    "    ranks = hits[:, -1] + 1\n",
    "    ranks = ranks.float()\n",
    "    rranks = torch.reciprocal(ranks)\n",
    "    mrr = torch.sum(rranks).data / targets.size(0)\n",
    "    return mrr\n",
    "    \n",
    "def calc(indices, targets, k=20):\n",
    "    _, indices = torch.topk(indices, k, -1)\n",
    "    recall = getRecall(indices, targets)\n",
    "    mrr = getMrr(indices, targets)\n",
    "    return recall, mrr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d0108042-1d40-4a3a-a800-820c7b8c3d65",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Evaluation(object):\n",
    "    def __init__(self, model, lossFunc=None, k=20):\n",
    "        self.model = model\n",
    "        self.lossFunc = lossFunc\n",
    "        self.topk = k\n",
    "        self.device = model.device\n",
    "\n",
    "    def evalute(self, validGenerator):\n",
    "        self.model.eval()\n",
    "        losses = []\n",
    "        recalls = []\n",
    "        mrrs = []\n",
    "        with torch.no_grad():\n",
    "            batchSize = validGenerator.batchSize\n",
    "            hidden = self.model.initHidden(batchSize)\n",
    "            for ii , (input, target, finishedMask, validMask) in tqdm(enumerate(validGenerator),\n",
    "                                                                     total=validGenerator.totalIters,\n",
    "                                                                     miniters=1000, position=0, leave=True):\n",
    "                input = input.to(self.device)\n",
    "                target = target.to(self.device)\n",
    "                hidden = self.model.resetHidden(hidden, finishedMask, validMask)\n",
    "                logit, hidden = self.model(input, hidden)\n",
    "               \n",
    "                if(self.lossFunc is not None):\n",
    "                    loss = self.lossFunc(logit, target)\n",
    "                    if(~np.isnan(loss.item())):\n",
    "                        losses.append(loss.item())\n",
    "\n",
    "                recall, mrr = calc(logit, target, k=self.topk)\n",
    "                recalls.append(recall)\n",
    "                mrrs.append(mrr.cpu().numpy())\n",
    "                \n",
    "        if(len(losses)):\n",
    "            meanLoss = np.mean(losses)\n",
    "        else :\n",
    "            meanLoss = 0\n",
    "                    \n",
    "        meanRecall = np.mean(recalls)\n",
    "        meanMrr = np.mean(mrrs)\n",
    "\n",
    "        return meanLoss, meanRecall, meanMrr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cb9c3185-7967-47f8-8bfc-a384b0130a4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trainer(object):\n",
    "    def __init__(self, model, trainGenerator, validGenerator, optim, lossFunc, topN, resultDir):\n",
    "                \n",
    "        self.topN = topN\n",
    "        self.model = model\n",
    "        self.optim = optim\n",
    "        self.lossFunc = lossFunc\n",
    "        self.resultDir = resultDir\n",
    "        self.device = model.device\n",
    "        self.evalutor = Evaluation(self.model, self.lossFunc, k=topN)\n",
    "        \n",
    "        self.trainGenerator = trainGenerator\n",
    "        self.validGenerator = validGenerator\n",
    "        \n",
    "    def train(self, nEpochs=10):\n",
    "        for epoch in range(nEpochs):\n",
    "            st = time.time()\n",
    "            print('Start Epoch #', epoch)\n",
    "            \n",
    "            trainLoss = self.trainEpoch(epoch)\n",
    "            validLoss, recall, mrr = self.evalutor.evalute(self.validGenerator)\n",
    "            \n",
    "            print(\"Epoch: {}, train loss: {:.4f}, validloss: {:.4f}, recall: {:.4f}, mrr: {:.4f}, time: {}\".format(epoch, trainLoss, validLoss, recall, mrr, time.time() - st))\n",
    "            self.saveModel(epoch, validLoss, trainLoss, recall, mrr) \n",
    "\n",
    "    def trainEpoch(self, epoch):\n",
    "        losses = []\n",
    "        self.model.train()\n",
    "        batchSize = float(self.trainGenerator.batchSize)\n",
    "        hidden = self.model.initHidden(batchSize)\n",
    "        negative = self.model.negative\n",
    "        \n",
    "        for _ , (input, target, finishedMask, validMask) in tqdm(enumerate(self.trainGenerator), total=self.trainGenerator.totalIters, miniters=1000, position=0, leave=True):\n",
    "            input = input.to(self.device)\n",
    "            target = target.to(self.device)            \n",
    "            hidden = self.model.resetHidden(hidden, finishedMask, validMask)\n",
    "            logit, hidden = self.model(input, hidden, target)\n",
    "\n",
    "            loss = self.lossFunc(logit, target)        \n",
    "            loss = (float(len(input)) / batchSize) * loss\n",
    "            \n",
    "            if(~np.isnan(loss.item())):\n",
    "                losses.append(loss.item())\n",
    "                loss.backward()\n",
    "                self.optim.step() \n",
    "                self.optim.zero_grad()\n",
    "            \n",
    "        meanLoss = np.mean(losses)\n",
    "        return meanLoss\n",
    "    \n",
    "    def saveModel(self, epoch, validLoss, trainLoss, recall, mrr):\n",
    "        checkPoints = {\n",
    "              'model': self.model,\n",
    "              'epoch': epoch,\n",
    "              'optim': self.optim,\n",
    "              'validLoss': validLoss,\n",
    "              'trainLoss': trainLoss,\n",
    "              'recall': recall,\n",
    "              'mrr': mrr\n",
    "        }\n",
    "        modelName = os.path.join(self.resultDir, \"model_{0:05d}.pt\".format(epoch))\n",
    "        torch.save(checkPoints, modelName)\n",
    "        print(\"Save model as %s\" % modelName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7119b37d-603a-4a00-9e2e-8b6dc0c69ff5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "404b1c2c-6075-4f28-9fe5-b0f66eb43e50",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputSize = trainDataSet.nItems \n",
    "outputSize = inputSize \n",
    "hiddenSize = 100   \n",
    "nLayers = 1 \n",
    "batchSize = 32 \n",
    "negative = True \n",
    "embeddingDim = -1 \n",
    "dropoutHidden = 0.0\n",
    "dropoutEmbed = 0.0\n",
    "sigma = 0.0\n",
    "initAsNormal = False\n",
    "cuda = torch.cuda.is_available() \n",
    "\n",
    "lr = 0.1\n",
    "weightDecay = 0.0\n",
    "momentum = 0.0\n",
    "bpreg = 1.0\n",
    "nEpochs = 10\n",
    "\n",
    "timeSort = True\n",
    "trainRandomOrder=False\n",
    "sampleAlpha=0.75\n",
    "trainNSample = 2048 \n",
    "validNSample = 0\n",
    "sampleStore = 10000000\n",
    "topN = 20\n",
    "\n",
    "resultDir = 'Results'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d849c0bb-c786-4ec5-9f2c-e43374aac778",
   "metadata": {},
   "outputs": [],
   "source": [
    "hiddenSize = 100\n",
    "nEpochs = 1\n",
    "batchSize = 32\n",
    "dropoutHidden = 0.0\n",
    "dropoutEmbed = 0.0\n",
    "lr = 0.2\n",
    "trainNSample = 2048\n",
    "sampleAlpha=0.0\n",
    "bpreg = 1.0\n",
    "timeSort = False\n",
    "embeddingDim = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a3da4430-53c0-4f71-8419-12bcad1f944a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GRU4Rec(inputSize=inputSize, outputSize=outputSize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0c4a7fcf-a569-42a1-9aa8-2fd804517dc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = Optimizer(model.parameters(), lr=lr, weightDecay=weightDecay, momentum=momentum)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bf94d6a7-ea5c-4b57-9453-8f25332b75b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "lossFunc = LossFunction(useCuda=cuda, bpreg=bpreg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "473f2583-30ed-4403-8a9a-0c0ac40be81d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ItemId\n",
      "5          1332\n",
      "11        25520\n",
      "12         9062\n",
      "13        28385\n",
      "14        20896\n",
      "          ...  \n",
      "302376        2\n",
      "304023        1\n",
      "306650        1\n",
      "307663        2\n",
      "326359        3\n",
      "Length: 4602, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "trainGenerator = DataGenerator(trainDataSet, nSample=trainNSample)\n",
    "validGenerator = DataGenerator(validDataSet, nSample=validNSample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4c5be85f-32b9-464f-b4bd-1d6c8301725b",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(model, trainGenerator=trainGenerator, validGenerator=validGenerator, optim=optimizer, lossFunc=lossFunc, topN=topN, resultDir=resultDir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6808a31a-dce0-43d1-a94d-a0c27a80d99e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Epoch # 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "147621it [49:42, 49.49it/s]                                                                                            \n",
      "49109it [06:06, 134.16it/s]                                                                                            "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, train loss: 0.7380, validloss: 0.7398, recall: 0.0547, mrr: 0.0111, time: 3349.142196893692\n",
      "Save model as Results\\model_00000.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "trainer.train(nEpochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e4c67a7-aa85-49d5-a1fc-3458476eb311",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
