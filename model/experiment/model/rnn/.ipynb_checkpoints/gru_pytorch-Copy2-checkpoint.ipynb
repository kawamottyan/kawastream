{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e5f5bde-3ca3-4262-85db-776a54590e7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "import torch.optim as optim\n",
    "\n",
    "import time\n",
    "import datetime\n",
    "import os\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1010198b-a602-46ec-88bc-b5e8f80a2b4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_dir = \"Results\"\n",
    "if not os.path.exists(result_dir):\n",
    "    os.makedirs(result_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "106cc485-510a-4dfa-bcb4-19359465c40b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(object):\n",
    "    def __init__(self, path, itemMap=None):\n",
    "        self.sessionKey = 'SessionId'\n",
    "        self.itemKey = 'ItemId'\n",
    "        self.timeKey = 'Time'\n",
    "        self.ItemIdx = 'ItemIdx'\n",
    "        self.data = pd.read_csv(path, sep=',', dtype={self.sessionKey: int, self.itemKey: int, self.timeKey: float})\n",
    "\n",
    "        # アイテムマップの作成し結合（評価時は学習データのアイテムマップを使用する）\n",
    "        self.itemMap = itemMap;\n",
    "        if (self.itemMap is None):\n",
    "            itemIds = self.data[self.itemKey].unique()\n",
    "            itemMap = pd.Series(data=np.arange(len(itemIds)), index=itemIds);\n",
    "            item_indices = itemMap[itemIds].values\n",
    "            itemDict = {\n",
    "                self.itemKey: itemIds,\n",
    "                self.ItemIdx: item_indices\n",
    "            }\n",
    "            self.itemMap = pd.DataFrame(itemDict)\n",
    "        self.data = pd.merge(self.data, self.itemMap, on=self.itemKey, how='inner')\n",
    "        \n",
    "        # セッション数の累積合計リスト（セッションの開始位置リスト）を取得\n",
    "        self.data.sort_values([self.sessionKey, self.timeKey], inplace=True)\n",
    "        session_nItem = self.data.groupby(self.sessionKey).size()\n",
    "        cum_session_nItem = session_nItem.cumsum()\n",
    "        self.sessionsArray = np.r_[0, cum_session_nItem.values]\n",
    "\n",
    "        self.nItems = len(self.itemMap)\n",
    "\n",
    "class DataGenerator():\n",
    "    def __init__(self, dataset, isTrain=True):\n",
    "        self.data = dataset.data\n",
    "        self.nItems = dataset.nItems\n",
    "        self.sessionsArray = dataset.sessionsArray\n",
    "\n",
    "        self.batchSize = 32\n",
    "        self.nSample = 2048   \n",
    "        self.sampleBuffer = 10000000\n",
    "        self.isTrain = isTrain\n",
    "\n",
    "        # 学習時は人気度に応じてネガティブサンプリングを行う\n",
    "        if self.isTrain:\n",
    "            self.popularArray = self.createPopular(dataset.itemMap, dataset.itemKey);\n",
    "        self.sessionByTime = np.argsort(self.data.groupby(dataset.sessionKey)[dataset.timeKey].min().values) \n",
    "        self.totalIters = ((len(self.data) - len(self.sessionsArray)) // self.batchSize)\n",
    "\n",
    "    def __iter__(self):\n",
    "        data_items = self.data.ItemIdx.values\n",
    "        sessions_array = self.sessionsArray\n",
    "        session_by_time = self.sessionByTime\n",
    "        \n",
    "        iterators = np.arange(self.batchSize)\n",
    "        max_iterator = iterators.max()\n",
    "        start_positions = sessions_array[session_by_time[iterators]]\n",
    "        end_positions = sessions_array[session_by_time[iterators] + 1]\n",
    "        num_sessions = len(sessions_array) - 1\n",
    "        finished_mask = (end_positions - start_positions <= 1)\n",
    "        valid_mask = (iterators < num_sessions)\n",
    "\n",
    "        # バッチサイズのセッション数ごとに繰り返す\n",
    "        finished = False\n",
    "        while not finished:\n",
    "            min_length = (end_positions - start_positions).min()\n",
    "            out_index = data_items[start_positions]\n",
    "\n",
    "            # セッションの最小値ごと、入力と出力（正解）のインデックスを作成\n",
    "            for i in range(min_length - 1):\n",
    "                in_index = out_index # (バッチサイズ,)\n",
    "                out_index = data_items[start_positions + i + 1] # (バッチサイズ,)\n",
    "                \n",
    "                # 学習時は人気度に応じてネガティブサンプリングを行う\n",
    "                if self.isTrain:\n",
    "                    negative_sample = self._get_sample()\n",
    "                    # target_values = np.hstack([out_index, negative_sample])\n",
    "\n",
    "                    input_tensor = torch.LongTensor(in_index)\n",
    "                    output_tensor = torch.LongTensor(out_index)\n",
    "                    negative_sample_tensor = torch.LongTensor(negative_sample)\n",
    "                    \n",
    "                    yield input_tensor, output_tensor, negative_sample_tensor, finished_mask, valid_mask\n",
    "                else:\n",
    "                    target_values = out_index # (バッチサイズ + ネガティブサンプル数,)\n",
    "                    \n",
    "                # input_tensor = torch.LongTensor(in_index) # 1次元 [バッチサイズ]\n",
    "                # target_tensor = torch.LongTensor(target_values) # 1次元 [バッチサイズ + ネガティブサンプル数]\n",
    "                \n",
    "\n",
    "                # yield input_tensor, target_tensor, finished_mask, valid_mask\n",
    "                \n",
    "                finished_mask[:] = False\n",
    "                valid_mask[:] = True\n",
    "            \n",
    "            start_positions += min_length - 1\n",
    "            finished_mask = (end_positions - start_positions <= 1)\n",
    "            num_finished = finished_mask.sum()\n",
    "            iterators[finished_mask] = max_iterator + np.arange(1, num_finished + 1)\n",
    "            max_iterator += num_finished\n",
    "            \n",
    "            valid_mask = (iterators < num_sessions)\n",
    "            \n",
    "            if valid_mask.sum() == 0:\n",
    "                finished = True\n",
    "                break\n",
    "            \n",
    "            iterators[~valid_mask] = 0\n",
    "            session_updates = session_by_time[iterators[finished_mask]]\n",
    "            start_positions[finished_mask] = sessions_array[session_updates]\n",
    "            end_positions[finished_mask] = sessions_array[session_updates + 1]\n",
    "            iterators = iterators[valid_mask]\n",
    "            start_positions = start_positions[valid_mask]\n",
    "            end_positions = end_positions[valid_mask]\n",
    "\n",
    "    def _get_sample(self):\n",
    "        # 用意したネガティブサンプルから一つづつ取り出す\n",
    "        if self.samplePointer == self.generatelength:\n",
    "            self.negativSamples = self.generateNegSamples(self.popularArray, self.generatelength)\n",
    "            self.samplePointer = 0\n",
    "        sample = self.negativSamples[self.samplePointer]\n",
    "        self.samplePointer += 1\n",
    "        return sample\n",
    "\n",
    "    def generateNegSamples(self, popularArray, length):\n",
    "        sample = np.searchsorted(popularArray, np.random.rand(self.nSample * length))\n",
    "        sample = sample.reshape((length, self.nSample))\n",
    "        return sample\n",
    "\n",
    "    def createPopular(self, itemMap, itemKey):\n",
    "        popularArray = self.data.groupby(itemKey).size()\n",
    "        itemIds = itemMap.loc[:, itemKey].values\n",
    "        \n",
    "        # 人気度の確率分布を作成\n",
    "        popularArray = popularArray[itemIds].values\n",
    "        popularArray = popularArray.cumsum() / popularArray.sum()\n",
    "\n",
    "        # ネガティブサンプリング\n",
    "        self.generatelength = (self.sampleBuffer // self.nSample) #サンプルバッファの総数 ÷ 一度に生成するサンプル数 = サンプル生成の回数\n",
    "        self.negativSamples = self.generateNegSamples(popularArray, self.generatelength)\n",
    "        self.samplePointer = 0\n",
    "\n",
    "        return popularArray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "953f0f6b-5202-45a7-b16c-7cac1ac6a725",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataFolder = '../../../data/'\n",
    "trainDataFile = 'Train.csv'\n",
    "validDataFile = 'Valid.csv'\n",
    "\n",
    "sessionKey = 'SessionId';\n",
    "itemKey = 'ItemId';\n",
    "timeKey = 'Time';\n",
    "\n",
    "trainPath = os.path.join(dataFolder, trainDataFile)\n",
    "validPath = os.path.join(dataFolder, validDataFile)\n",
    "\n",
    "trainDataSet = Dataset(trainPath)\n",
    "validDataSet = Dataset(validPath, itemMap=trainDataSet.itemMap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2aaedc4-bed8-4a46-929d-c162369afff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GRU4Rec(nn.Module):\n",
    "    def __init__(self, inputSize, outputSize):\n",
    "\n",
    "        super(GRU4Rec, self).__init__()\n",
    "\n",
    "        self.inputSize = inputSize\n",
    "        self.outputSize = outputSize\n",
    "        self.batchSize = 32\n",
    "        self.hiddenSize = 100\n",
    "        self.nLayers = 1\n",
    "        self.sigma = 0.0\n",
    "        self.negative = True\n",
    "\n",
    "        self.embeddingDim = -1\n",
    "        \n",
    "        self.dropoutHidden = 0.0\n",
    "        self.dropoutEmbed = 0.0\n",
    "        self.initAsNormal = False\n",
    "        \n",
    "        self.device = torch.device('cuda' if torch.cuda.is_available()  else 'cpu')\n",
    "\n",
    "        self.onehotBuffer = torch.FloatTensor(self.batchSize, self.outputSize)\n",
    "        \n",
    "        self.gru = nn.GRU(self.inputSize, self.hiddenSize, self.nLayers, bias=False, dropout=self.dropoutHidden)\n",
    "        self.linear = nn.Linear(self.hiddenSize, self.outputSize)\n",
    "        self.Tanh = nn.Tanh()\n",
    "\n",
    "        self.initParams();\n",
    "        \n",
    "        self = self.to(self.device)\n",
    "\n",
    "    def forward(self, input, hidden, target=None):\n",
    "        # 1-of-Nエンコーディング\n",
    "        embedded = self.onehotEncode(input) # 2次元 [バッチサイズ, インプットサイズ]\n",
    "        embedded = embedded.unsqueeze(0) # 3次元 [1, バッチサイズ, インプットサイズ]\n",
    "        \n",
    "        output, hNew = self.gru(embedded, hidden) # 3次元 [1, バッチサイズ, 隠し層数]\n",
    "        output = output.view(-1, output.size(-1)) # 2次元 [バッチサイズ, 隠し層数]\n",
    "        output = self.linear(output) # 2次元 [バッチサイズ, アウトプットサイズ]\n",
    "        output = output[:, target.view(-1)] # 2次元 [バッチサイズ, ネガティブサンプル数 + バッチサイズ]\n",
    "        output = self.Tanh(output)\n",
    "        \n",
    "        return output, hNew\n",
    "\n",
    "    def onehotEncode(self, input):\n",
    "        self.onehotBuffer.zero_()\n",
    "        index = input.view(-1, 1)\n",
    "        onehot = self.onehotBuffer[:len(index)].scatter_(1, index, 1)\n",
    "        \n",
    "        return onehot\n",
    "\n",
    "    def initHidden(self, batchSize):\n",
    "        h0 = torch.zeros(self.nLayers, int(batchSize), self.hiddenSize).to(self.device)\n",
    "        return h0\n",
    "    \n",
    "    def resetHidden(self, hidden, finishedMask, validMask):\n",
    "        if any(finishedMask):\n",
    "            hidden[:, finishedMask, :] = 0 \n",
    "\n",
    "        if any((~validMask)):\n",
    "            hidden = hidden[:, validMask, :]\n",
    "            \n",
    "        return hidden.data;\n",
    "    \n",
    "    def initParams(self):\n",
    "        for name, param in self.gru.named_parameters():\n",
    "            if 'weight' in name:\n",
    "                WR, WZ, WN = param.chunk(3, 0)\n",
    "                self.initMatrix(WR)\n",
    "                self.initMatrix(WZ)\n",
    "                self.initMatrix(WN)\n",
    "    \n",
    "            elif 'bias' in name :\n",
    "                param.data.zero_()\n",
    "        \n",
    "        self.initMatrix(self.linear.weight)\n",
    "        self.linear.bias.data.zero_()\n",
    "        \n",
    "    def initMatrix(self, param):\n",
    "        \n",
    "        shape = list(param.shape)\n",
    "        sigma = np.sqrt(6.0 / np.sum(shape))\n",
    "        param.data.uniform_(-sigma, sigma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f35f42eb-85b1-4f4e-a6a0-a69ab013911f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LossFunction(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LossFunction, self).__init__()\n",
    "        self._lossFn = TOP1Loss()\n",
    "\n",
    "    def forward(self, input, target=None):\n",
    "        return self._lossFn(input, target)\n",
    "\n",
    "class TOP1Loss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(TOP1Loss, self).__init__()\n",
    "    def forward(self, input, target=None):\n",
    "        diff = -(input.diag().view(-1, 1).expand_as(input) - input)\n",
    "        loss = torch.sigmoid(diff).mean() + torch.sigmoid(input ** 2).mean()\n",
    "        return loss\n",
    "\n",
    "class BPRLoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(BPRLoss, self).__init__()\n",
    "\n",
    "    def forward(self, input, target=None):\n",
    "        diff = input.diag().view(-1, 1).expand_as(input) - input\n",
    "        loss = -torch.mean(F.logsigmoid(diff))\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "009bef42-3623-4380-86c1-0e38731049dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Optimizer:\n",
    "    def __init__(self, params):\n",
    "        self.optimizer = optim.Adagrad(params, lr=0.05, weight_decay=0, eps=1e-6)\n",
    "\n",
    "    def zero_grad(self):\n",
    "        self.optimizer.zero_grad()\n",
    "\n",
    "    def step(self):\n",
    "        self.optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25a31eba-5ed2-461a-a80c-78f5181f0ff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getRecall(indices, targets): \n",
    "    targets = targets.view(-1, 1).expand_as(indices)\n",
    "    hits = (targets == indices).nonzero()\n",
    "    if len(hits) == 0:\n",
    "        return 0\n",
    "    n_hits = (targets == indices).nonzero()[:, :-1].size(0)\n",
    "    recall = float(n_hits) / targets.size(0)\n",
    "    return recall\n",
    "\n",
    "def getMrr(indices, targets):\n",
    "    tmp = targets.view(-1, 1)\n",
    "    targets = tmp.expand_as(indices)\n",
    "    hits = (targets == indices).nonzero()\n",
    "    ranks = hits[:, -1] + 1\n",
    "    ranks = ranks.float()\n",
    "    rranks = torch.reciprocal(ranks)\n",
    "    mrr = torch.sum(rranks).data / targets.size(0)\n",
    "    return mrr\n",
    "    \n",
    "def calc(indices, targets, k=20):\n",
    "    _, indices = torch.topk(indices, k, -1)\n",
    "    recall = getRecall(indices, targets)\n",
    "    mrr = getMrr(indices, targets)\n",
    "    return recall, mrr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0108042-1d40-4a3a-a800-820c7b8c3d65",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Evaluation(object):\n",
    "    def __init__(self, model, lossFunc=None, k=20):\n",
    "        self.model = model\n",
    "        self.lossFunc = lossFunc\n",
    "        self.topk = k\n",
    "        self.device = model.device\n",
    "\n",
    "    def evalute(self, validGenerator):\n",
    "        self.model.eval()\n",
    "        losses = []\n",
    "        recalls = []\n",
    "        mrrs = []\n",
    "        with torch.no_grad():\n",
    "            batchSize = validGenerator.batchSize\n",
    "            hidden = self.model.initHidden(batchSize)\n",
    "            for ii , (input, target, finishedMask, validMask) in tqdm(enumerate(validGenerator),\n",
    "                                                                     total=validGenerator.totalIters,\n",
    "                                                                     miniters=1000, position=0, leave=True):\n",
    "                input = input.to(self.device)\n",
    "                target = target.to(self.device)\n",
    "                hidden = self.model.resetHidden(hidden, finishedMask, validMask)\n",
    "                logit, hidden = self.model(input, hidden)\n",
    "               \n",
    "                if(self.lossFunc is not None):\n",
    "                    loss = self.lossFunc(logit, target)\n",
    "                    if(~np.isnan(loss.item())):\n",
    "                        losses.append(loss.item())\n",
    "\n",
    "                recall, mrr = calc(logit, target, k=self.topk)\n",
    "                recalls.append(recall)\n",
    "                mrrs.append(mrr.cpu().numpy())\n",
    "                \n",
    "        if(len(losses)):\n",
    "            meanLoss = np.mean(losses)\n",
    "        else :\n",
    "            meanLoss = 0\n",
    "                    \n",
    "        meanRecall = np.mean(recalls)\n",
    "        meanMrr = np.mean(mrrs)\n",
    "\n",
    "        return meanLoss, meanRecall, meanMrr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb9c3185-7967-47f8-8bfc-a384b0130a4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trainer(object):\n",
    "    def __init__(self, model, trainGenerator, validGenerator, optim, lossFunc, topN, resultDir):\n",
    "                \n",
    "        self.topN = topN\n",
    "        self.model = model\n",
    "        self.optim = optim\n",
    "        self.lossFunc = lossFunc\n",
    "        self.resultDir = resultDir\n",
    "        self.device = model.device\n",
    "        self.evalutor = Evaluation(self.model, self.lossFunc, k=topN)\n",
    "        \n",
    "        self.trainGenerator = trainGenerator\n",
    "        self.validGenerator = validGenerator\n",
    "        \n",
    "    def train(self, nEpochs=10):\n",
    "        for epoch in range(nEpochs):\n",
    "            st = time.time()\n",
    "            print('Start Epoch #', epoch)\n",
    "            \n",
    "            trainLoss = self.trainEpoch(epoch)\n",
    "            validLoss, recall, mrr = self.evalutor.evalute(self.validGenerator)\n",
    "            \n",
    "            print(\"Epoch: {}, train loss: {:.4f}, validloss: {:.4f}, recall: {:.4f}, mrr: {:.4f}, time: {}\".format(epoch, trainLoss, validLoss, recall, mrr, time.time() - st))\n",
    "            self.saveModel(epoch, validLoss, trainLoss, recall, mrr) \n",
    "\n",
    "    def trainEpoch(self, epoch):\n",
    "        losses = []\n",
    "        self.model.train()\n",
    "        batchSize = float(self.trainGenerator.batchSize)\n",
    "        hidden = self.model.initHidden(batchSize)\n",
    "        \n",
    "        for _ , (input, target, negative, finishedMask, validMask) in tqdm(enumerate(self.trainGenerator), total=self.trainGenerator.totalIters, miniters=1000, position=0, leave=True):\n",
    "            input = input.to(self.device)\n",
    "            target = target.to(self.device)            \n",
    "            hidden = self.model.resetHidden(hidden, finishedMask, validMask)\n",
    "            logit, hidden = self.model(input, hidden, target) # logit [バッチサイズ、バッチサイズ]\n",
    "\n",
    "            loss = self.lossFunc(logit, target)   \n",
    "            loss = (float(len(input)) / batchSize) * loss\n",
    "            if(~np.isnan(loss.item())):\n",
    "                losses.append(loss.item())\n",
    "                loss.backward()\n",
    "                self.optim.step() \n",
    "                self.optim.zero_grad()\n",
    "            \n",
    "        meanLoss = np.mean(losses)\n",
    "        return meanLoss\n",
    "    \n",
    "    def saveModel(self, epoch, validLoss, trainLoss, recall, mrr):\n",
    "        checkPoints = {\n",
    "              'model': self.model,\n",
    "              'epoch': epoch,\n",
    "              'optim': self.optim,\n",
    "              'validLoss': validLoss,\n",
    "              'trainLoss': trainLoss,\n",
    "              'recall': recall,\n",
    "              'mrr': mrr\n",
    "        }\n",
    "        modelName = os.path.join(self.resultDir, \"model_{0:05d}.pt\".format(epoch))\n",
    "        torch.save(checkPoints, modelName)\n",
    "        print(\"Save model as %s\" % modelName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7119b37d-603a-4a00-9e2e-8b6dc0c69ff5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd5d5f8c-c0c0-45d5-82c8-c6cac4b24a94",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputSize = trainDataSet.nItems \n",
    "outputSize = inputSize "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3da4430-53c0-4f71-8419-12bcad1f944a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GRU4Rec(inputSize=inputSize, outputSize=outputSize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c4a7fcf-a569-42a1-9aa8-2fd804517dc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = Optimizer(model.parameters())   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf94d6a7-ea5c-4b57-9453-8f25332b75b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "lossFunc = LossFunction()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "473f2583-30ed-4403-8a9a-0c0ac40be81d",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainGenerator = DataGenerator(trainDataSet)\n",
    "validGenerator = DataGenerator(validDataSet, isTrain=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf58b034-1ed3-4fdb-bcc4-499527dbb54f",
   "metadata": {},
   "outputs": [],
   "source": [
    "topN = 20\n",
    "resultDir = 'Results'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c5be85f-32b9-464f-b4bd-1d6c8301725b",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(model, trainGenerator=trainGenerator, validGenerator=validGenerator, optim=optimizer, lossFunc=lossFunc, topN=topN, resultDir=resultDir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99d47626-435a-4681-8901-f602f800a058",
   "metadata": {},
   "outputs": [],
   "source": [
    "nEpochs = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6808a31a-dce0-43d1-a94d-a0c27a80d99e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "trainer.train(nEpochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8b8cc11-c33c-41dd-a289-1d78b6aa7cb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class BPRLoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(BPRLoss, self).__init__()\n",
    "\n",
    "    def forward(self, input):\n",
    "        # 仮定: input[:, 0] が正例の予測値、input[:, 1:] が負例の予測値\n",
    "        positive_preds = input[:, 0].unsqueeze(1)  # 形状を [バッチサイズ, 1] に変更\n",
    "        negative_preds = input[:, 1:]\n",
    "\n",
    "        # 正例と負例の予測値の差\n",
    "        diff = positive_preds - negative_preds\n",
    "\n",
    "        # BPR損失の計算\n",
    "        loss = -torch.mean(F.logsigmoid(diff))\n",
    "        return loss\n",
    "\n",
    "# サンプルの入力値を作成（バッチサイズ = 2, 正例数 = 32, 負例数 = 2048）\n",
    "sample_input = torch.randn(32, 2080)  # ランダムな予測値\n",
    "\n",
    "# 損失関数のインスタンスを作成\n",
    "loss_function = BPRLoss()\n",
    "\n",
    "# 損失を計算\n",
    "loss = loss_function(sample_input)\n",
    "\n",
    "# 期待される出力値（損失）\n",
    "loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27f6c928-a499-4880-9352-59d40527e096",
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_preds = sample_input[:, 0].unsqueeze(1) \n",
    "positive_preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e1b77ae-7ec6-4f49-ba29-020656455878",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_input = torch.randn(32, 2080)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c98f7ea-c2d9-476a-9997-bff915fb135a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49f5c1cb-f334-4c86-882b-5babc1efd285",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_input[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0154c0e-53a1-4563-b63c-0050723d00a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_input[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee14fddf-685b-4f05-b069-92e74b98377f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_input[:, 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e76c05b-e8e7-4fc0-a3be-3d73145873c4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
